{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb412e24-d63e-4f52-ad4f-e0ddebfe3d76",
   "metadata": {},
   "source": [
    "# Standalone local Spark cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ef53e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a956889b-53ee-424f-9c1d-3b7a9ca7d252",
   "metadata": {},
   "source": [
    "We can start a standalone master server by executing:\n",
    "\n",
    "```sh\n",
    "$SPARK_HOME/sbin/start-master.sh\n",
    "```\n",
    "\n",
    "Once started, we can find on the master's web UI (`localhost:8080` by default) a `spark://HOST:PORT` URL, which we can use to connect workers to it, or pass as the `master` argument to `SparkContext` or `SparkSession`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9962327c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/24 11:44:17 WARN Utils: Your hostname, GRAD0365UBUNTU resolves to a loopback address: 127.0.1.1; using 192.168.68.103 instead (on interface wlp0s20f3)\n",
      "24/02/24 11:44:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/24 11:44:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://GRAD0365UBUNTU:7077\") \\\n",
    "    .appName(\"test\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "864070ad-13be-4d73-a153-8f1838754622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.68.103:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://GRAD0365UBUNTU:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f38dbb0eeb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9a5f7d-a447-44e1-8bf5-5951e88e398e",
   "metadata": {},
   "source": [
    "At this point, if we want to execute a Spark job we get an error, since we do not have any worker running. Similarly to what we previously did, we can start one or more workers and connect them to the master via:\n",
    "\n",
    "```bash\n",
    "$SPARK_HOME/sbin/start-worker.sh <master-spark-URL>\n",
    "```\n",
    "\n",
    "We can verify on the Spark UI that there is one active worker and we can execute jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ef495",
   "metadata": {},
   "source": [
    "## Create trips dataframe\n",
    "\n",
    "Let's recreate the steps we did in the `.03_spark_sql.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b481226d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|VendorID|lpep_pickup_datetime|lpep_dropoff_datetime|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|ehail_fee|improvement_surcharge|total_amount|payment_type|trip_type|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|       2| 2020-01-12 18:15:04|  2020-01-12 18:19:52|                 N|         1|          41|          41|              1|         0.78|        5.5|  0.0|    0.5|      1.58|         0.0|     null|                  0.3|        7.88|           1|        1|                 0.0|\n",
      "|       2| 2020-01-31 20:24:10|  2020-01-31 20:31:51|                 N|         1|         173|          70|              1|         0.98|        7.0|  0.5|    0.5|       0.0|         0.0|     null|                  0.3|         8.3|           2|        1|                 0.0|\n",
      "|       2| 2020-01-07 08:16:53|  2020-01-07 08:41:39|                 N|         1|          74|         236|              1|          2.7|       16.0|  0.0|    0.5|      3.91|         0.0|     null|                  0.3|       23.46|           1|        1|                2.75|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet(\"../data/pq/green/*/*\")\n",
    "df_yellow = spark.read.parquet(\"../data/pq/yellow/*/*\")\n",
    "df_green.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e053f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- trip_type: integer (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2923017e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_yellow.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb3c2c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'lpep_pickup_datetime',\n",
       " 'lpep_dropoff_datetime',\n",
       " 'store_and_fwd_flag',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'ehail_fee',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'payment_type',\n",
       " 'trip_type',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b66b5c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'tpep_pickup_datetime',\n",
       " 'tpep_dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'store_and_fwd_flag',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yellow.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60c71c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DOLocationID',\n",
       " 'PULocationID',\n",
       " 'RatecodeID',\n",
       " 'VendorID',\n",
       " 'congestion_surcharge',\n",
       " 'extra',\n",
       " 'fare_amount',\n",
       " 'improvement_surcharge',\n",
       " 'mta_tax',\n",
       " 'passenger_count',\n",
       " 'payment_type',\n",
       " 'store_and_fwd_flag',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'total_amount',\n",
       " 'trip_distance'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_green.columns) & set(df_yellow.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd58870a",
   "metadata": {},
   "source": [
    "To create a global taxi dataframe:\n",
    "* Rename pickup and droppoff datetime columns to have the same in both dataframes.\n",
    "* Obtain common columns from both yellow and green taxi dataframes, keeping them in order.\n",
    "* Add a column that indicates the service type (yellow or green taxi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e565a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = df_green \\\n",
    "    .withColumnRenamed(\"lpep_pickup_datetime\", \"pickup_datetime\") \\\n",
    "    .withColumnRenamed(\"lpep_dropoff_datetime\", \"dropoff_datetime\")\n",
    "\n",
    "df_yellow = df_yellow \\\n",
    "    .withColumnRenamed(\"tpep_pickup_datetime\", \"pickup_datetime\") \\\n",
    "    .withColumnRenamed(\"tpep_dropoff_datetime\", \"dropoff_datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dd719a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns = []\n",
    "\n",
    "yellow_columns = set(df_yellow.columns)\n",
    "\n",
    "for col in df_green.columns:\n",
    "    if col in yellow_columns:\n",
    "        common_columns.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "217f738c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'store_and_fwd_flag',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'payment_type',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f449751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_green_sel = df_green \\\n",
    "    .select(common_columns) \\\n",
    "    .withColumn(\"service_type\", F.lit(\"green\"))\n",
    "\n",
    "df_yellow_sel = df_yellow \\\n",
    "    .select(common_columns) \\\n",
    "    .withColumn(\"service_type\", F.lit(\"yellow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be83ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_data = df_green_sel.unionAll(df_yellow_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17b905a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:================================================>        (17 + 3) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|service_type|   count|\n",
      "+------------+--------+\n",
      "|       green| 2304517|\n",
      "|      yellow|39649199|\n",
      "+------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_trips_data.groupBy(\"service_type\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ccb7aa",
   "metadata": {},
   "source": [
    "## SQL queries\n",
    "\n",
    "Once we have the global dataframe with both yellow and green data, we can do queries on it.\n",
    "\n",
    "To do that, we need to register our dataframe as a table first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c136d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_data.createOrReplaceTempView(\"trips_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fbfc658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+--------------------+------------+\n",
      "|VendorID|    pickup_datetime|   dropoff_datetime|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type|congestion_surcharge|service_type|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+--------------------+------------+\n",
      "|       2|2020-01-12 18:15:04|2020-01-12 18:19:52|                 N|         1|          41|          41|              1|         0.78|        5.5|  0.0|    0.5|      1.58|         0.0|                  0.3|        7.88|           1|                 0.0|       green|\n",
      "|       2|2020-01-31 20:24:10|2020-01-31 20:31:51|                 N|         1|         173|          70|              1|         0.98|        7.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         8.3|           2|                 0.0|       green|\n",
      "|       2|2020-01-07 08:16:53|2020-01-07 08:41:39|                 N|         1|          74|         236|              1|          2.7|       16.0|  0.0|    0.5|      3.91|         0.0|                  0.3|       23.46|           1|                2.75|       green|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+--------------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * \n",
    "FROM trips_data\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58454a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=================================>                      (12 + 8) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|service_type|count(1)|\n",
      "+------------+--------+\n",
      "|       green| 2304517|\n",
      "|      yellow|39649199|\n",
      "+------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT service_type, COUNT(1) \n",
    "FROM trips_data\n",
    "GROUP BY service_type\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbc25722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:==================================================>     (18 + 2) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+------------------------------------+--------------------------+------------------------+\n",
      "|revenue_zone|      revenue_month|service_type|revenue_monthly_fare|revenue_monthly_extra|revenue_monthly_mta_tax|revenue_monthly_tip_amount|revenue_monthly_tolls_amount|revenue_monthly_improvement_surcharge|revenue_monthly_total_amount|revenue_monthly_congestion_surcharge|avg_montly_passenger_count|avg_montly_trip_distance|\n",
      "+------------+-------------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+------------------------------------+--------------------------+------------------------+\n",
      "|         127|2020-02-01 00:00:00|       green|  21571.680000000008|               890.75|                  495.0|                   1050.52|           488.8000000000003|                    345.0000000000035|          25119.149999999816|                               264.0|        1.1945837512537614|       4.583894472361811|\n",
      "|           9|2020-02-01 00:00:00|       green|   7251.639999999994|               643.25|                   25.0|         7.720000000000001|          183.20000000000005|                    77.99999999999984|           8193.510000000002|                                2.75|        1.1219512195121952|      445.80187969924833|\n",
      "|          47|2020-01-01 00:00:00|       green|  16630.150000000034|               1192.0|                  160.0|        42.230000000000004|           523.0000000000003|                   210.90000000000228|           18770.42999999991|                                11.0|         1.177685950413223|      4.6450000000000005|\n",
      "|         180|2020-02-01 00:00:00|       green|  2817.1500000000005|                178.0|                   15.0|                     12.52|                       37.47|                    30.00000000000003|          3090.1399999999985|                                 0.0|        1.0606060606060606|                  5.7353|\n",
      "|          53|2020-01-01 00:00:00|       green|   6281.649999999992|               330.25|                   49.0|         39.21999999999999|          102.50000000000001|                    68.39999999999971|           6873.770000000006|                                2.75|        1.2417582417582418|       6.929710743801653|\n",
      "|         128|2020-01-01 00:00:00|       green|  3261.3300000000004|                158.0|                   35.5|                     82.25|          104.04000000000002|                    34.50000000000003|           3714.020000000003|                                27.5|        1.0169491525423728|      7.0232800000000015|\n",
      "|         150|2020-01-01 00:00:00|       green|   9996.160000000005|                627.5|                   98.0|         97.86999999999999|          149.14000000000004|                   109.49999999999932|          11082.069999999976|                                 0.0|        1.1147540983606556|       5.393588516746412|\n",
      "|         263|2020-01-01 00:00:00|       green|   8987.339999999997|                561.0|                 124.55|        315.27000000000004|           335.0600000000002|                   127.19999999999915|           10684.16999999999|                              239.25|        1.4293478260869565|       5.264249422632796|\n",
      "|          19|2020-01-01 00:00:00|       green|   7798.880000000002|                377.0|                   42.0|                      6.66|          174.40000000000006|                    67.49999999999972|           8466.440000000008|                                 0.0|                  1.046875|      7.8507818930041156|\n",
      "|          81|2020-02-01 00:00:00|       green|   17340.13000000002|               1127.5|                  110.5|                     20.75|           991.5900000000004|                    149.3999999999993|          19743.770000000004|                                 0.0|        1.2653061224489797|       8.627810760667906|\n",
      "|          22|2020-02-01 00:00:00|       green|  17398.530000000006|               1148.5|                   99.5|         74.39999999999999|          478.57000000000016|                   164.99999999999915|           19367.24999999998|                                2.75|        1.1590909090909092|       6.001778523489931|\n",
      "|          40|2020-02-01 00:00:00|       green|  21840.030000000006|                896.5|                  831.0|        3179.4299999999994|           397.8000000000002|                    517.8000000000081|          28638.259999999806|                              967.75|        1.2492456246228123|      2.8544061962134237|\n",
      "|          37|2020-02-01 00:00:00|       green|  23375.710000000006|              1982.75|                  229.0|                    428.95|           527.5100000000002|                    284.1000000000018|           26942.41999999999|                              104.25|        1.2318059299191375|        4.49492110453649|\n",
      "|         186|2020-01-01 00:00:00|       green|  1539.2300000000002|                85.25|                    6.0|                       0.0|           97.92000000000002|                   13.800000000000011|                      1742.2|                                 0.0|        1.6666666666666667|       9.389565217391304|\n",
      "|          71|2020-02-01 00:00:00|       green|  26571.900000000085|               2603.5|                  195.0|                     30.23|          465.54000000000025|                    308.4000000000027|           30183.96999999992|                                 5.5|                    1.1875|       4.293813708260108|\n",
      "|          38|2020-02-01 00:00:00|       green|   8637.039999999988|               605.75|                   34.0|                       5.0|                      165.24|                    77.39999999999982|           9526.380000000005|                                 0.0|        1.2173913043478262|       8.019010989010992|\n",
      "|         216|2020-02-01 00:00:00|       green|  19758.420000000016|               1245.0|                  110.0|                    102.96|          424.25000000000017|                   195.29999999999984|          21843.379999999946|                                 5.5|        1.1793893129770991|       6.703884785819798|\n",
      "|         238|2020-01-01 00:00:00|       green|   5397.990000000001|                403.5|                   20.0|                       0.0|          124.68000000000002|                   61.199999999999775|           6007.370000000002|                                 0.0|                       1.2|       6.460536585365854|\n",
      "|         126|2020-01-01 00:00:00|       green|  11827.840000000017|               766.75|                  110.5|        101.86999999999999|           458.2800000000002|                    145.1999999999998|          13425.339999999993|                                11.0|                     1.275|       5.187806691449814|\n",
      "|         192|2020-02-01 00:00:00|       green|   6302.809999999998|               376.75|                   44.5|                    353.89|          54.129999999999995|                    71.69999999999989|           7220.180000000002|                                2.75|        1.2681159420289856|       5.143769230769231|\n",
      "+------------+-------------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+------------------------------------+--------------------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    -- Revenue grouping \n",
    "    PULocationID AS revenue_zone,\n",
    "    date_trunc('month', pickup_datetime) AS revenue_month, \n",
    "    service_type, \n",
    "\n",
    "    -- Revenue calculation \n",
    "    SUM(fare_amount) AS revenue_monthly_fare,\n",
    "    SUM(extra) AS revenue_monthly_extra,\n",
    "    SUM(mta_tax) AS revenue_monthly_mta_tax,\n",
    "    SUM(tip_amount) AS revenue_monthly_tip_amount,\n",
    "    SUM(tolls_amount) AS revenue_monthly_tolls_amount,\n",
    "    SUM(improvement_surcharge) AS revenue_monthly_improvement_surcharge,\n",
    "    SUM(total_amount) AS revenue_monthly_total_amount,\n",
    "    SUM(congestion_surcharge) AS revenue_monthly_congestion_surcharge,\n",
    "\n",
    "    -- Additional calculations\n",
    "    AVG(passenger_count) AS avg_montly_passenger_count,\n",
    "    AVG(trip_distance) AS avg_montly_trip_distance\n",
    "FROM\n",
    "    trips_data\n",
    "GROUP BY\n",
    "    1, 2, 3\n",
    "\"\"\")\n",
    "\n",
    "df_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c1f578",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3f0ebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/24 12:18:16 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED\n",
      "24/02/24 12:18:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exiting due to error from cluster scheduler: Master removed our application: KILLED\n",
      "\tat org.apache.spark.errors.SparkCoreErrors$.clusterSchedulerError(SparkCoreErrors.scala:218)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.error(TaskSchedulerImpl.scala:923)\n",
      "\tat org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.dead(StandaloneSchedulerBackend.scala:154)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint.markDead(StandaloneAppClient.scala:262)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:169)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "df_result.coalesce(1).write.parquet(\"../data/report/revenue\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf12510d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
